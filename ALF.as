/*   Copyright 2009 Music and Entertainment Technology Laboratory - Drexel University      Licensed under the Apache License, Version 2.0 (the "License");   you may not use this file except in compliance with the License.   You may obtain a copy of the License at       http://www.apache.org/licenses/LICENSE-2.0   Unless required by applicable law or agreed to in writing, software   distributed under the License is distributed on an "AS IS" BASIS,   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.   See the License for the specific language governing permissions and   limitations under the License.*/package{		import flash.utils.ByteArray;	import flash.events.SampleDataEvent;	import flash.events.IOErrorEvent;	import flash.events.ProgressEvent;	import flash.media.Sound;	import flash.media.SoundChannel;		import flash.net.*;	import flash.events.Event;	import flash.utils.Endian;	import flash.events.IOErrorEvent;	import flash.events.EventDispatcher;	import flash.utils.*;	import flash.errors.IOError;	import DATF;		/*		Class: ALF				The Audio processing Library for Flash. ALF plays an audio file (MP3 or wav) using the dynamic audio functionality 		of Actionscript3 and provides methods for obtaining audio features and manipulating the audio output stream on a frame by frame basis.	*/	public class ALF extends EventDispatcher{				// Sound playback				var audio:Sound;		var mp3Audio:Sound;		var audioCh:SoundChannel;		var mp3Bytes:ByteArray;		var playBytes:ByteArray;		var loadedData:URLLoader;		public var numCh:uint;		public var fs:uint;				private var leftSample:Number;		private var rightSample:Number;				private var mp3Position:uint = 0;		private var wavPosition:uint;		private var fileExt:String;						private var waveLoader:URLLoader;		private var mp3Loader:URLLoader;		private var STEREO:Boolean = false;		private var READY:Boolean = false;		private var STOP:Boolean = false;		private var PAUSE:Boolean = false;		private var CONTINUE:Boolean = true;				// Framing		public var chVal:Number;		public var numSamplesToPlay:Number;		public var frameSize:uint = 4096;		public var frameSizeBytes;		// DATF		private var DSP:DATF;				//C Memory stuff		private var cRAM:ByteArray;		private var audioPtrs:Array;		private const sizeofFloat:Number = 4;				//Buffer Status vars		private var leftBufferStatus:Array;		private	var rightBufferStatus:Array;		private	var numSamplesLeft:int;		private var numSamplesRight:int;				// Events		public const NEW_FRAME:String = "newFrame";		public const FILE_LOADED:String = "audioFileLoaded";		public const FILE_COMPLETE:String = "audioFileCompleted";				// Utility		private var i:uint;		private var tempInt:int;			private var tempNum:Number;		private var verbose:Boolean;				// Features		public var inten:Number, cent:Number, band:Number, roll:Number, flux:Number;		public var harmAmps:Array, harmFreqs:Array, magArr:Array;		/*									Topic: Usage						ALF is a library which whose functions return audio features and perform other operations on an audio file 	on a frame by 			frame basis. In this curren version, an event, NEW_FRAME, is dispatched whenever a new audio frame begins. To synchronize 			visual events with audio, use NEW_FRAME as you might use ENTER_FRAME (event that signals a new frame in the 			timeline). A simple example that plays a file and plots a feature is shown below:						Topic: Example						(start code)			class ALFTester extends Sprite{							var intensity:Number;				var sprite:Sprite = new Sprite();				var count:uint = 0;				var frameSize:uint = 2048;							public function ALFTest(){										// Set line parameters to plot a feature in realtime					line.graphics.lineStyle( 2, 0x000000, 1000);					line.moveTo(0,400);										// Variables to pass as initialization parameters					var str:String = "Test Song.mp3";															// Initialize ALF					myALF = new ALF(str, 22, false);										// 22 fps					myALF.addEventListener(myALF.FILE_LOADED, audioLoaded);					// Event that says the audio file has finished loading					myALF.addEventListener(myALF.NEW_FRAME, onFrame);						// Event that signals a new frame										myALF.addEventListener(myALF.FILE_COMPLETE, audioFinished);				// Event that signals the song has finished playing				}								// Once the file has finished loading, begin playback				public function audioLoaded(event:Event):void{								myALF.startAudio();				}									// This function is called every time a new audio/video frame is processed				public function onFrame(event:Event):void{										// Draw line to new point					intensity = myALF.getIntensity();					line.graphics.lineTo(count, 400 - inten/50);										count++;				}								public function audioFinished(event:Event):void{					trace('Playback complete');				}						}			(end)						*/		/*			Group: Constructor						Constructor: ALF						Constructor for ALF.						Parameters:							filename - The filename of the audio file to play.				framesPerSecond - The frame rate in frames per second. Only 22 and 11 fps are available in this release. See below.				_verbose - When true, prints the .wav file header in the output window. The header contains information such as the 						   sample rate, bit rate, number of channels, size, etc.							Notes:							The frame rate is based off the event NEW_FRAME (<ALF Events>). For this first version, it is the only option available,				subsequent versions will also employ the ENTER_FRAME event and most rates available in Flash/Actionscript will be 				supported. Current frame rates are listed below:								- 22 FPS				- 11 FPS		*/		public function ALF(filename:String, framesPerSecond:uint, _verbose:Boolean){						switch(framesPerSecond){										case 11:	frameSize = 4096; 								break;																case 22:	frameSize = 2048;								break;													default:	trace("Invalid frame rate. Valid frame rates are 22fps and 11fps.");								break;			}						//Save parameter values			verbose = _verbose;						//initialize the sound objects			audio = new Sound();			audioCh = new SoundChannel();									//Find file extension			fileExt = filename.substr(filename.length - 3, 4);			fileExt = fileExt.toLowerCase();						switch(fileExt){								case "wav": 	frameSizeBytes = frameSize*2;								waveLoader = new URLLoader();											// Initialize URL Looader															waveLoader.dataFormat = URLLoaderDataFormat.BINARY;						// Set to binary format								waveLoader.addEventListener(Event.COMPLETE, waveLoaded);				// Event for when file is loaded								audio.addEventListener(SampleDataEvent.SAMPLE_DATA, wavAudioCallback); 	// Add event for each audio frame								var waveRequest:URLRequest = new URLRequest(filename);					// Set filename to load													// Attempting to read in the wave file								try {																		waveLoader.load(waveRequest);								} catch(error:IOError) {									trace('Error getting wave file');								}																		break;								case "mp3":		// Initialize mp3 objects								var mp3Request:URLRequest = new URLRequest(filename);					// Load filename								mp3Bytes = new ByteArray();												// For raw samples from file																mp3Bytes.endian = Endian.LITTLE_ENDIAN;																	playBytes = new ByteArray();											// For playback of endian converted samples								playBytes.endian = Endian.BIG_ENDIAN;																mp3Audio = new Sound();													// Sound object for audio file								STEREO = true;								fs = 44100;																// Attempting to read in the MP3 file								try{									mp3Audio.load(mp3Request);																			} catch(error:IOError){										trace('Error reading MP3 file');								}								mp3Audio.addEventListener(Event.COMPLETE, mp3Loaded);					// Dispatched when file is loaded									audio.addEventListener(SampleDataEvent.SAMPLE_DATA, mp3AudioCallback); 	// Dispatched on each audio frame																				break;								default:		trace('Invalid file type! ALF only supports .wav and .mp3 files');			}										}				/******************************************************************************		*		*							AUDIO PLAYBACK FUNCTIONS		*		******************************************************************************/						/*			Group: Audio Playback					Function: startAudio						A function to begin playback of an audio file. The FILE_LOADED event (<ALF Events>) must have been dispatched and received by the class 			instantiating ALF prior to calling startAudio.						See Also:						<stopAudio()>,				<pauseAudio()>,				<Example>		*/		public function startAudio():void{ 											// When audio has already been played then stopped.			if(READY && STOP){				switch(fileExt){										case 	"wav":  audioCh = audio.play();									audio.addEventListener(SampleDataEvent.SAMPLE_DATA, wavAudioCallback);																		audioCh.addEventListener(Event.SOUND_COMPLETE, audioComplete);									break;												case	"mp3":	audioCh = audio.play();									audio.addEventListener(SampleDataEvent.SAMPLE_DATA, mp3AudioCallback);																		audioCh.addEventListener(Event.SOUND_COMPLETE, audioComplete);									break;				}															}			// First time being played or continuing after a pause 			else if (READY){ 				audioCh = audio.play();				audioCh.addEventListener(Event.SOUND_COMPLETE, audioComplete);							}else if(!READY){				trace('ALF not initialized. Do not call startAudio() until file has loaded.');			}						STOP = false;			PAUSE = false;		}				/*			Function: pauseAudio						A function to resume playback of an audio file. This function adds the SampleDataEvent 			associated with the audio object. This funciton is only to be called after stopAudio has been called.						See Also:						<startAudio()>,				<stopAudio()>		*/				public function pauseAudio():void{			audioCh.stop();						PAUSE = true;		}		private function continueAudio():void{						switch(fileExt){								case 	"wav": 	loadedData.data.position = 44;										// Reset to beginning of file								audioCh = audio.play();												// Start playback								audioCh.addEventListener(Event.SOUND_COMPLETE, audioComplete);								break;										case	"mp3":	mp3Position = 0;													// Reset to beginning of file 								mp3Bytes.length = 0;												// Reset byte array								mp3Position = mp3Audio.extract(mp3Bytes,frameSize,mp3Position);		// Extract audio								audioCh = audio.play();												// Start playback								audioCh.addEventListener(Event.SOUND_COMPLETE, audioComplete);										break;			}					}				/*			Function: stopAudio						A function to stop playback of an audio file. This function removes the SampleDataEvent associated with the audio object. 			The object will no longer call for more data to playback. To restart playback (add the listener again) use restartAudio. 			If audio stops because the end of the audio file has been reached, the FILE_COMPLETE event (<ALF Events>) will be dispatched.						See Also:						<startAudio()>,				<Example>		*/		public function stopAudio():void{						DSP.clearAudioBuffers();						switch(fileExt){								case 	"wav":  audioCh.stop();							// Stopping playback																loadedData.data.position = 44;			// Reset to beginning of file																break;										case	"mp3":	audioCh.stop();							// Stopping playback																			mp3Bytes.length = 0;					// Reset ByteArray								mp3Position = 0;						// Reset to beginning of file								mp3Position += mp3Audio.extract(mp3Bytes,frameSize,mp3Position);																break;			}						STOP = true;		}						//Parse wave header and begin playback		private function waveLoaded(evt:Event):void {						// Establishing reference to object containing data read in from URLRequest			loadedData = URLLoader(evt.target);						/*********************** Parsing wave file header ************************/						var wfh_chunkID:String = loadedData.data.readMultiByte(4,"utf");						loadedData.data.endian = Endian.LITTLE_ENDIAN;			var wfh_chunkSize:uint = loadedData.data.readUnsignedInt(); 			loadedData.data.endian = Endian.BIG_ENDIAN;			var wfh_format:String = loadedData.data.readMultiByte(4,"utf");			var wfh_subChunk1D:String = loadedData.data.readMultiByte(4,"iso-8859-1");			loadedData.data.endian = Endian.LITTLE_ENDIAN;				var wfh_subChunk1Size:int = loadedData.data.readInt()			var wfh_audioFormat:int = loadedData.data.readShort();			var wfh_channels:int = loadedData.data.readShort();			var wfh_fs:int = loadedData.data.readUnsignedInt();			var wfh_bytesPerSec:int = loadedData.data.readUnsignedInt();			var wfh_blockAlign:int = loadedData.data.readShort()			var wfh_bits:int = loadedData.data.readUnsignedShort();			loadedData.data.endian = Endian.BIG_ENDIAN;					var wfh_dataChunkSignature:String = loadedData.data.readMultiByte(4,'iso-8859-1')			loadedData.data.endian = Endian.LITTLE_ENDIAN;						var wfh_numBytes:int = loadedData.data.readInt();			var wfh_numSamples:int = wfh_numBytes/(wfh_bits/8);						//set the number of samples per Channel			var wfh_numSamplesPerChannel = wfh_numSamples/wfh_channels;			/**************************** End Header Parsing **********************************/						if(verbose){							trace('----------------------------------------------');				trace('Wave File Information');				trace('ChunkID: '+ wfh_chunkID);				trace('ChunkSize: '+ wfh_chunkSize);				trace('Format: '+ wfh_format);							trace('SubChunk1D: '+ wfh_subChunk1D);				trace('SubChunk1Size: '+ wfh_subChunk1Size);							trace('Audio Format: '+ wfh_audioFormat);							trace('Channels: '+ wfh_channels);				trace('SampleRate: '+ wfh_fs);				trace('Bytes/Second: '+ wfh_bytesPerSec);							trace('BlockAlign: '+ wfh_blockAlign);				trace('Bits/Sample: '+ wfh_bits);							trace('Data Chunk Signature: '+ wfh_dataChunkSignature);							trace('Data Chunk Length: ' + wfh_numBytes + " bytes     " + wfh_numSamples + " samples");				trace('Byte position after reading header info: '+ loadedData.data.position);				trace('----------------------------------------------\n');						}															fs = wfh_fs;								// Store sample frequency			numCh = wfh_channels;						// Store number of channels			if(wfh_channels == 2) STEREO = true;		// Set mono/stereo			if(!(fs == 22050 || fs == 44100)){trace('UNSUPPORTED SAMPLE RATE! ALF supports only 22kHz or 44.1kHz sample rates');}						//Initialize the DATF			DSP = new DATF(frameSize, STEREO, fs);						//get the Reference to the cRAM data			cRAM = DSP.getCRAM();			audioPtrs = DSP.getChAudPtrs();			//Set ready for playback flag			READY = true;			dispatchEvent(new Event(FILE_LOADED));		}								//Load MP3 file and play		private function mp3Loaded(evt:Event):void{			//Initilize the DATF			DSP = new DATF(frameSize, STEREO, fs);						// Get pointers to C memory			cRAM = DSP.getCRAM();			audioPtrs = DSP.getChAudPtrs();												mp3Bytes.position = 0;			mp3Position += mp3Audio.extract(mp3Bytes,frameSize,mp3Position);			// Extract samples											//Set ready for playback flag			READY = true;			dispatchEvent(new Event(FILE_LOADED));		}				// Plays wav audio samples		private function wavAudioCallback(evt:SampleDataEvent):void {						//as long as there is data left to read into C...we do that and process the data			//by dispatching a new event.			if(!(loadedData.data.bytesAvailable == 0)) {				DSP.loadWavFrame(loadedData);				dispatchEvent(new Event(NEW_FRAME));			} 						//check the status of the buffers to see if they're ready for playback....			leftBufferStatus = DSP.checkAudioBuffer("left");			if(STEREO) {				rightBufferStatus  = DSP.checkAudioBuffer("right");			}			if(STEREO) {				numSamplesToPlay = Math.min(leftBufferStatus[1], rightBufferStatus[1]);			}else {				numSamplesToPlay = leftBufferStatus[1];			}									if(STEREO){								switch(fs){										case 44100:		for(i = 0; i < numSamplesToPlay; i++){																				cRAM.position = audioPtrs[0] + i*sizeofFloat;		//position for leftCh										leftSample = cRAM.readFloat();										cRAM.position = audioPtrs[1] + i*sizeofFloat;		//position for rightCh										rightSample = cRAM.readFloat();																				// Write to output stream										evt.data.writeFloat(leftSample);										evt.data.writeFloat(rightSample);									}																		break;														case 22050:		for(i = 0; i < numSamplesToPlay; i++){																				cRAM.position = audioPtrs[0] + i*sizeofFloat;		//position for leftCh										leftSample = cRAM.readFloat();										cRAM.position = audioPtrs[1] + i*sizeofFloat;		//position for rightCh										rightSample = cRAM.readFloat();																				// Write to output stream										evt.data.writeFloat(leftSample);										evt.data.writeFloat(rightSample);										evt.data.writeFloat(0);										evt.data.writeFloat(0);									}									break;				}			}else if (!STEREO){								switch(fs){										case 44100: 	for(i = 0; i < numSamplesToPlay; i++){																				cRAM.position = audioPtrs[0] + i*sizeofFloat;		//position for leftCh										leftSample = cRAM.readFloat();																				// Write to output stream										evt.data.writeFloat(leftSample);										evt.data.writeFloat(leftSample);									}									break;														case 22050:		for(i = 0; i < numSamplesToPlay; i++){																				cRAM.position = audioPtrs[0] + i*sizeofFloat;		//position for leftCh										leftSample = cRAM.readFloat();																				// Write to output stream										evt.data.writeFloat(leftSample);										evt.data.writeFloat(leftSample);										evt.data.writeFloat(0);										evt.data.writeFloat(0);									}									break;				}			}else{				trace('ERROR: ALF can only handle mono or stereo files.');			}							// Signal a new frame is coming			DSP.newFrame();		}				// Plays mp3 audio samples		private function mp3AudioCallback(evt:SampleDataEvent):void {			// Dispatch event to signal a new audio frame			if(mp3Bytes.length > 0){				mp3Bytes.position = 0;				DSP.loadMP3Frame(mp3Bytes);				// Load the audio frame into the C buffer				dispatchEvent(new Event(NEW_FRAME));				}																						leftBufferStatus = DSP.checkAudioBuffer("left");			rightBufferStatus  = DSP.checkAudioBuffer("right");					numSamplesToPlay = Math.min(leftBufferStatus[1], rightBufferStatus[1]);			for(i = 0; i < numSamplesToPlay; i++){														cRAM.position = audioPtrs[0] + i*sizeofFloat;		//position for leftCh				leftSample = cRAM.readFloat();				cRAM.position = audioPtrs[1] + i*sizeofFloat;		//position for rightCh				rightSample = cRAM.readFloat();								// Write samples				evt.data.writeFloat(leftSample);				evt.data.writeFloat(rightSample);			}																			//Extract audio data from sound object			mp3Bytes.length = 0;						mp3Position += mp3Audio.extract(mp3Bytes, frameSize, mp3Position);			// Extract samples								// Signal a new frame is coming			DSP.newFrame();		}						// Called when the file has completed		private function audioComplete(evt:Event):void{			DSP.clearAudioBuffers();						if(CONTINUE){				continueAudio();							}else{				switch(fileExt){										case "wav":	loadedData.data.position = 44; 											// Reset to beginning of file								break;													case "mp3": mp3Bytes.length = 0;													// Reset ByteArray								mp3Position = 0;														// Reset to beginning of file								mp3Position += mp3Audio.extract(mp3Bytes,frameSize,mp3Position);		// Extract samples																							break;				}			}			STOP = true;			dispatchEvent(new Event(FILE_COMPLETE));	// Event to tell user file has finished		}				/******************************************************************************		*		*						  DATF INTERFACE FUNCTIONS		*		******************************************************************************/					/*						Group: Audio Features						Values returned from all features are dependent upon the input audio. The style, genre, 			and instrumentation play a significant role in 	the numbers returned from each function 			but the production value (i.e. compression/mastering) also weighs heavily into what range			of values is returned, especially for the intensity.						Function: getIntensity						This function calculates the intensity of the current audio frame loaded into ALF. The 			intensity is a measure of how much energy is in the current	frame. If there are many 			instruments playing loudly, this value will be large, for an ambient section of a song,			this value will be small.						Returns:								An Number which is the intensity value for the current frame. The range of values 				will be dependent mostly upon the production				value of the audio file. 							Notes:							Production quality and post-processing significantly effects this value.		*/				public function getIntensity():Number{						inten = DSP.getIntensity();			return inten;		}				/*			Function: getBrightness			Brightness is an approximation of the timbre. If there is high frequency content, such as			a horn section, then the brightness is higher, for low frequency such as drum and bass, the			brightness value will be lower.						Returns:						A Number which is the brightness in (Hz) value for the current frame. Typical values will 			be around several thousand hertz. The range of values will be between 0 and the sample rate 			divided by 2. For an MP3, the values will be from 0 - 22050. For a wav file, the sample frequency 			can be viewed in the .wav file 	header which can be printed out. For info on printing the 			.wav file header see <ALF>.		*/				public function getBrightness():Number{						cent = DSP.getCentroid();			return cent;		}						/*			Function: getFlux			This function calculates the change in frequency content for each frame. Instantaneous changes in 			the audio content(both new sounds and sudden quiet) will produce large flux values.						Returns:						A Number which is the flux value for the current frame.		*/				public function getFlux():Number{						flux = DSP.getFlux();			return flux;		}								/*			Function: getBandwidth					This function calculates the bandwidth of the current audio frame loaded into ALF. The 			bandwidth represents the range of frequencies present in the audio at the current frame.			This value gives an estimate of the instrumentation. A full band with drums, vocals, keys,			bass, guitar, synth, etc. will have a large bandwidth. An a solo cello performance will have			a smaller bandwidth.						Returns:								An Number which is the bandwidth (Hz) value for the current frame. Typical values 				will be around several thousand hertz.The range of values will be between 0 and the 				sample rate divided by 2. For an MP3, the values will be from 0 - 22050. For a wav 				file, the sample frequency can be viewed in the .wav file header which can be printed 				out. For info on printing the .wav file header see <ALF>.		*/			public function getBandwidth():Number{						band = DSP.getBandwidth();			return band;		}				/*			Function: getRolloff						This function calculates the frequency ceiling of the current frame. Rolloff is the frequency below which			most of the instruments lie.						Returns:								An Number which is the rolloff value for the current frame. The range of values will be 				between 0 and the sample rate divided by 2. For an MP3, the values will be from 0 - 22050. 				For a wav file, the sample frequency can be viewed in the wave file header which can be printed out.						*/				public function getRolloff():Number{						roll = DSP.getRolloff();			return roll;		}				/*			Function: getSpectrum						This function calculates the frequency spectrum of the current frame.						Parameters:							fftSize - The number of DFT points used in performing the Fourier Transform. If you are				unfamiliar with the Fourier Transform use default (0), this is he quickest option and uses 				the next power of 2 greater than or equal to the frameSize.  						Returns:								An Array of spectral amplitudes of length (fftSize/2 + 1).						Notes:							This is the magnitude spectrum, only real values are returned.		*/			public function getSpectrum(fftSize:Number):Array{						if(fftSize == 0){				fftSize = frameSize;			}						magArr = [];			magArr = DSP.magSpectrum(fftSize);						return magArr;		}				/*		getHarmonics				This function computes the partials assoicated with the audio spectrum				Returns:						Nothing. getHarmFreqs and getHarmAmps return the partial frequencies and amplitudes.					See Also:						<getHarmonicFrequencies()>,			<getHarmonicAmplitudes()>		*/				public function getHarmonics(numHarms:uint):void {			DSP.getHarmonics(numHarms);		}		/*			getHarmonicFrequencies						Returns the harmoinc Frequencies generated from the getHarmonics call. getHarmonics must be called before			this.						Returns:								An Array of frequencies.							See Also:							<getHarmonicHarmonics()>,				<getHarmonicAmplitudes()>		*/						public function getHarmonicFrequencies():Array {					harmFreqs = DSP.getHarmonicFrequencies();			return harmFreqs;		}				/*			getHarmonicAmplitudes						Returns the harmonics amplitudes generated from the getHarmonics call. getHarmoincs must be called before			this.						Returns:								An array of amplitudes.							See Also:							<getHarmonics()>,				<getHarmonicFrequencies()>		*/				public function getHarmonicAmplitudes():Array {			harmAmps = DSP.getHarmonicAmplitudes();			return harmAmps;		}				/*			Group: Audio Processing Functions					Function: reverb						This function adds reverb to the output stream.						Parameters:								activate - A string value indicating whether reverb should be turned on or off.					"on" adds reverb to the processing chain. It will persist unless it is turned off.					"off" removes reverb from the processing chain. It will remain off until it is turned on again.				processCh - An int specifying the channel reverb should be applied to					"1" applies it just to the left channel (default in DATF)					"2" applies it to both channels (if you're working with a Stereo file)				level - A value from 1-4 (1 is the lowest, 4 is the highest) specifying the level of reverb to be applied.				roomType - a string specifying the type of room to simulate. The sound source and listener locations assume					that the source is near the front of the room and the listener (mic) is at the center.					"small" - simulates a room of dimensions 10X10X8 in feet					"big"- simulates a room of dimensions 20X20X8 in feet					"hall"- simulates a 'hall' of dimensions 30X50X30 in feet		*/		public function reverb(activate:String, processCh:int, level:uint, roomType:String):void {						var roomX:Number, roomY:Number, roomZ:Number, srcX:Number, srcY:Number, srcZ:Number,				micX:Number, micY:Number, micZ:Number;			var echoStrength:Number;						switch(level) {				case 1:					echoStrength = 0.25;					break;				case 2:					echoStrength = 0.50;					break;				case 3:					echoStrength = 0.75;					break;				case 4:					echoStrength = 1.00;					break;				default:					echoStrength = 0.0;					break;			}						switch(roomType) {				case "small":						roomX = 3; roomY = 3; roomZ = 2.4; //makes the room 10X10X8 in feet						srcX = 1.5, srcY = 1, srcZ = 1.5;						micX = 1.5, micY = 2, micZ = 1.5;					break;				case "big":						roomX = 6; roomY = 6; roomZ = 3; //makes the room 20X20X10 in feet						srcX = 3, srcY = 1, srcZ = 1.5;						micX = 3, micY = 4.5, micZ = 1.5;					break;				case "hall":						roomX = 9; roomY = 15; roomZ = 9; //makes the hall 30X50X30 in feet						srcX = 4.5, srcY = .5, srcZ = 1.5;						micX = 4.5, micY = 7.5, micZ = 1.5;					break;				default:						roomX = 3; roomY = 3; roomZ = 2.4; //makes the room 10X10X8 in feet						srcX = 1.5, srcY = 1, srcZ = 1.5;						micX = 1.5, micY = 2.8, micZ = 1.5;					break;			}						trace('activate ' + activate + ' processCh' + processCh + ' level: ' + level);			trace('echoStrength: '+ echoStrength + ' roomType: ' + roomType);			trace('roomX '+ roomX + ' roomY '+ roomY + ' roomZ ' + roomZ);			trace('srcX '+ srcX + ' srcY '+ srcY + ' srcZ ' + srcZ);			trace('micX '+ micX + ' micY '+ micY + ' micZ ' + micZ);			trace('');						DSP.addReverb(activate, processCh, level, roomX, roomY, roomZ,							  srcX, srcY, srcZ, micX, micY, micZ);					}				//un documented function for full reverb access through ALF		public function reverbDemo(activate:String, processCh:int, level:Number,							   roomX:Number, roomY:Number, roomZ:Number,							   srcX:Number, srcY:Number, srcZ:Number,							   micX:Number, micY:Number, micZ:Number):void{						DSP.addReverb(activate, processCh, level,						  roomX, roomY, roomZ,						  srcX, srcY, srcZ,						  micX, micY, micZ);		}						}		/*		Group: Events			Topic: ALF Events				There are three events ALF dispatches that are essential to properly using the library.									FILE_LOADED - 	This event is dispatched when the audio file has finished loading. No other function calls should be made after							the ALF object is created until *after* this event is received. For more information see 							http://livedocs.adobe.com/flash/9.0/ActionScriptLangRefV3/flash/media/Sound.html#event:complete.							Note that the load time will depend upon whether you are using Flash or AIR. AIR can access the local file system, 							therefore load times will be short. If using Flash, the time it takes for this listener to dispatch after the 							constructor, <ALF>, is called will vary significantly depending on filesize, filetype, and server/network speed. 										NEW_FRAME - 	This event is sychronized with the SampleDataEvent in the Actionscript Sound class. For more information							see http://livedocs.adobe.com/flex/3/langref/flash/events/SampleDataEvent.html.										FILE_COMPLETE - This event is dispatched when the audio file has finished playing. When there is no more data for the Sound object							to process (i.e. the last frame is reached) this event will be released.									See Also:					<DATF->newFrame()>	*/}