/*   Copyright 2009 Music and Entertainment Technology Laboratory - Drexel University      Licensed under the Apache License, Version 2.0 (the "License");   you may not use this file except in compliance with the License.   You may obtain a copy of the License at       http://www.apache.org/licenses/LICENSE-2.0   Unless required by applicable law or agreed to in writing, software   distributed under the License is distributed on an "AS IS" BASIS,   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.   See the License for the specific language governing permissions and   limitations under the License.*//*		*/package{		import cmodule.ALFPackage.CLibInit;		import flash.utils.ByteArray;	import flash.events.SampleDataEvent;	import flash.net.*;	import flash.utils.Endian;	import flash.utils.getTimer;	import flash.events.IOErrorEvent;			/*		Class: DATF				The DSP Audio Toolkit for Flash. The DATF is a wrapper class that provides simple interfacing with C/C++ DSP functions via Adobe Alchemy. 	*/	public class DATF{				// Basic members		private var frameSize:uint;		private var fftSize:uint;		private var frameSizeBytes:uint;		private var samplesToWrite:int;				private var fs:uint;		private static var i:int;		private var numCh:uint = 1;		private const sizeofFloat:Number = 4;		private var STEREO:Boolean;				// Array Handling		var chPtrArray:Array;					//Array of the shared AS/C pointers of the AudioChannel class in ALFPackage.cpp		var chAudArray:Array;					//Array to the audio frame in the AudioChannel class in ALFPackage.cpp		var chSamplesPtrArray:Array;			//Array that tracks pointers indicating the number of samples contained in audio Frame for each AudioChannel object		var leftCh:Array;						//pointers of the left channel		var rightCh:Array;						//pointers of the right channel		var chPtr:int, magPtr:int;		var temp:int;		var tempNum:Number;		var chVal:Number;		var initPos:Number;						// Position of URL Loader data passed to DATF		var ch:uint;							// For looping through the channels if stereo		// C Library		public static var lib:Object;			// Object that is used to 		public static var libLoader:CLibInit;	// Class that exposes functionality from your C code			public static var cRAM:ByteArray;		// Shared AS/C memory				// Storage variables		var FFTArray:Array, IFFTArray:Array, magArray:Array, harmFreqs:Array, harmAmps:Array;				//Timer		var time1:Number;		var time2:Number;				/*			Topic: Usage						The DATF is designed for developers who want more control over the dynamic audio capabilities of Actionscript. For simpler 'out of the box'			functionality, use the <ALF>. The DATF provides a means to access a variety of DSP functions that are written in C/C++ and then compiled with 			the Alchemy enabled g++ compiler to create bytecode that is optimized for the Actionscript Virtual Machine. The ALFPackage.swc file you include			in your project (process outlined in the <Introduction>) contains all the functions that are called from the DATF. A simple example is given below.			Note that this is a scaled down version of what ALF does. Again, the reason for using DATF rather than ALF is to implement the dynamic audio 			playback in a different manner.						Topic: Example						(start code)						class myClass{								var DSP:DATF;								var mp3Bytes:ByteArray:				var playBytes:ByteArray:							var audio:Sound;				var mp3Audio:Sounc;				var audioCh:SoundChannel;								var cRAM:ByteArray;				var audioPtrs:Array;				var leftBufferStatus:Array;				var rightBufferStatus:Array;											const var STEREO:Boolean = true;				const var frameSize:uint = 2048;				const var fs:uint = 44100;								public function myClass(){										var song:String = "Testsong.mp3";										var mp3Request:URLRequest = new URLRequest(song);						// Load filename					mp3Bytes = new ByteArray();												// For raw samples from file					mp3Bytes.endian = Endian.LITTLE_ENDIAN;																			audio = new Sound();													// Sound object for playback					mp3Audio = new Sound();													// Sound object for audio file sample extraction					audioCh = new SoundChannel();																					cRAM = new ByteArray();					leftBufferStatus = new Array();					rightBufferStatus = new Array();					audioPtrs = new Array();										// Attempting to read in the MP3 file					try{						sourceAudio.load(mp3Request);																} catch(e:IOError){							trace('Error reading MP3 file');					}					mp3Audio.addEventListener(Event.COMPLETE, mp3Loaded);									audio.addEventListener(SampleDataEvent.SAMPLE_DATA, mp3AudioCallback); 	// Dispatched on each audio frame					}				//Load MP3 file and play				private function mp3Loaded(evt:Event):void{							//Initilize the DATF					DSP = new DATF(frameSize, STEREO, fs);										cRAM = DSP.getCRAM();														// Pointer to shared AS/C memory					audioPtrs = DSP.getChAudPtrs();												// Pointers to the L/R channels																	// Read first frame					mp3Bytes.position = 0;					mp3Position += mp3Audio.extract(mp3Bytes,frameSize,mp3Position);			// Extract samples									}								private function mp3AudioCallback(evt:SampleDataEvent):void {							mp3Bytes.position = 0;					DSP.loadMP3Frame(mp3Bytes);				// Load the audio frame into the C buffer																											// You must check to see if audio is being synthesized by DATF (i.e. using reverb)							leftBufferStatus = DSP.checkAudioBuffer("left");															rightBufferStatus  = DSP.checkAudioBuffer("right");							numSamplesToPlay = Math.min(leftBufferStatus[1], rightBufferStatus[1]);					// Find how many samples to play							for(i = 0; i < numSamplesToPlay; i++){																		cRAM.position = audioPtrs[0] + i*sizeofFloat;		//position for leftCh						leftSample = cRAM.readFloat();						cRAM.position = audioPtrs[1] + i*sizeofFloat;		//position for rightCh						rightSample = cRAM.readFloat();												evt.data.writeFloat(leftSample);						evt.data.writeFloat(rightSample);					}																							//Extract audio data from sound object					mp3Bytes.length = 0;					mp3Position += mp3Audio.extract(mp3Bytes,frameSize,mp3Position);			// Extract samples							mp3Bytes.position = 0;														// Reset pointer													//Tell C there is a new frame coming					DSP.newFrame();				}			}						(end code)					*/				/*			Group: Constructor					Constructor: DATF						Constructor to create a DATF object. This constructor initializes the shared memory between Actionscript and C/C++. Only mono and stereo					files are accepted. The C/C++ library is included via the line 						:import cmodule.ALFPackage.CLibInit;												Parameters:							_frameSize - The frame size				_numCh - The number of channels (mono or stereo)				_fs - The sampling frequency		*/		public function DATF(_frameSize:uint, _STEREO:Boolean, _fs:uint):void{						frameSize = _frameSize;			fftSize = frameSize;			frameSizeBytes = 2 * frameSize;			STEREO = _STEREO;			fs = _fs;						if(STEREO){ numCh = 2;}						//Alchemy Interfacing			var ns:Namespace = new Namespace("cmodule.ALFPackage");	// get the namespace of the C module			cRAM = (ns::gstate).ds;									// cRAM is a variable representing the shared ALCHEMY/C memory			libLoader = new CLibInit();								// Creating the class that exposes functionality from C			lib = libLoader.init();									// init() function initializes the C code caling your main() function in C						//Arrays containing poiter values to shared AS/C memory			chPtrArray = new Array()			chAudArray = new Array();			chSamplesPtrArray = new Array();						//Initialize left channel			leftCh = new Array();			leftCh = lib.initAudioChannelC("leftCh", fs, frameSize);  	// calls the Alchemy library to initialize memory			chPtrArray.push(leftCh[0]);										chAudArray.push(leftCh[1]);			chSamplesPtrArray.push(leftCh[2]);						//Initialize right channel if necessary			if(STEREO){								numCh = 2;				rightCh = new Array();					rightCh = lib.initAudioChannelC("rightCh", fs, frameSize);							chPtrArray.push(rightCh[0]);				chAudArray.push(rightCh[1]);				chSamplesPtrArray.push(rightCh[2]);			}			//initialize storage arrays			harmAmps = new Array();			harmFreqs = new Array();			FFTArray = new Array();			IFFTArray = new Array();			magArray = new Array();			/*						trace('initializing DATF:');			trace('');			trace('frameSize = '+frameSize, 'sample rate = '+fs, 'numCh = '+numCh);*/		}				public function getCRAM():ByteArray {			//reference to the shared cRAM memory			return cRAM;		}				public function getChAudPtrs():Array {			//returns reference to array containing channel audio pointers so we can read directly from those buffers			return chAudArray;		}				/**********************************************		* DATF Functions		***********************************************/		/*			Group: Audio Framing					Function: setFrame						This function copies the data from a ByteArray into the shared Actionscript/C memory.						Parameters:							audio - A ByteArray object containing raw sample data.				numSamples - The number of samples to be read into the buffer.				type - A string specifying 'float' or 'short' datatype.						See Also:							<DATF>		*/		public function setFrame(audio:ByteArray,  numSamples:uint, type:String):void{						//Save position of input audio			initPos = audio.position;						type = type.toLowerCase();			switch(type){				 				case "float":	for(i = 0; i < numSamples; i++){														for(ch = 0; ch < numCh; ch++){																cRAM.position = chAudArray[ch] + sizeofFloat*i;																chVal = audio.readFloat();													cRAM.writeFloat(chVal);									}								}												case "short":	for(i = 0; i < numSamples; i++){														for(ch = 0; ch < numCh; ch++){																cRAM.position = chAudArray[ch] + sizeofFloat*i;																tempNum = audio.readShort();												chVal = tempNum/32768;										cRAM.writeFloat(chVal);									}								}																	default:		trace("Invalid datatype");			}																			//Reset audio position before returning			audio.position = initPos;		}				/*						This function loads raw sample data from a .wav file into the shared C/Actionscript memory. When the URLLoader object is passed to the 			function, the read position is saved in a local variable and then reset once the function is complete. It is not necessary to 			keep track of the pointer position using this function. loadWavFrame will read the number of samples specified by the variable			frameSize. For stereo files, a sample is two values (left and right channels). This case is handled automatically if the proper			number of channels is specified when the DATF object is created.						Parameters:							audio - A URLLoader object containing a wave file with the position set somewhere in the data block.						See Also:							<DATF>		*/		public function loadWavFrame(audio:URLLoader):void{									if(audio.data.bytesAvailable > frameSizeBytes*numCh) {				samplesToWrite = frameSize;			} else {				samplesToWrite = audio.data.bytesAvailable/(numCh*2);				//to get rid of erroneous samples, we should clear the audioFrames				for(ch = 0; ch < numCh; ch++) {					lib.clearAudioFrameC(chPtrArray[ch]);				}			}						for(i = 0; i < samplesToWrite; i++) {								for(ch = 0; ch < numCh; ch++){						cRAM.position = chAudArray[ch] + sizeofFloat*i;						temp = audio.data.readShort();						chVal = temp/32768.0;									cRAM.writeFloat(chVal);				}							}						//This informs the AudioChannel Class how many samples are in the audioFrame Buffer			for(ch = 0; ch < numCh; ch++){				cRAM.position = chSamplesPtrArray[ch];				cRAM.writeInt(samplesToWrite);			}					}				/*						This function loads raw sample data from an MP3 file into the shared C/Actionscript memory. When the ByteArray object is passed 			to the 	function, the read position is saved in a local variable and then reset once the function is complete. It is not necessary to 			keep track of the pointer position using this function. loadMP3Frame will read the number of samples specified by the variable			frameSize. For stereo files, a sample is two values (left and right channels). This case is handled automatically if the proper			number of channels is specified when the DATF object is created.						Parameters:							audio - A ByteArray containing a the extracted samples from an MP3 file.							See Also:							<DATF>											Notes:							The sample data must first be extracted from the .mp3 file using the Sound.extract() method in the Actionscript library. For more 				information see http://help.adobe.com/en_US/AS3LCR/Flash_10.0/flash/media/Sound.html.						*/				public function loadMP3Frame(audio:ByteArray):void{			if(audio.bytesAvailable/8 == frameSize){				samplesToWrite = frameSize;			}else{				samplesToWrite = audio.bytesAvailable/8;					for(ch = 0; ch < numCh; ch++) {					lib.clearAudioFrameC(chPtrArray[ch]);				}			}						for(i = 0; i < samplesToWrite; i++) {								for(ch = 0; ch < numCh; ch++){					cRAM.position = chAudArray[ch] + sizeofFloat*i;					cRAM.writeFloat(audio.readFloat());								}						}			for(ch = 0; ch < numCh; ch++){				cRAM.position = chSamplesPtrArray[ch];				cRAM.writeInt(samplesToWrite);			}		}				/*			Group: Basic Library Functions					Function: FFT						Performs the Fast Fourier Transform (FFT) on the current frame.						Parameters:							fftSize - The nuber of DFT points to be used in calculating the Fourier Transform.						Returns:							An array of alternating real and complex values.						See Also:							<IFFT()>,				<magSpectrum()>		*/		public function FFT(fftSize:uint):Array{			lib.performFFTC(chPtrArray[0]);						return FFTArray;		}				/*			Function: IFFT						Performs an Inverse Fourier Transform on the current frame.						Parameters:							fftSize - The number of IDFT points to be used in calculating the Inverse Fourier Transform. For reconstruction						  of a signal, this number needs to be the same as the fftSize used when the forward transform was calculated.						Returns:							An array of sample points.												See Also:							<FFT()>		*/		public function IFFT(fftSize:uint):Array{			lib.performIFFTC(chPtrArray[0]);						return IFFTArray;		}				/*			Function: magSpectrum						Calculates the magnitude spectrum from the complex frequency spectrum. To calclate a DFT of another size other than			the framSize, use <FFT()> first and then call magSpec().						See Also:							<FFT()>		*/		public function magSpectrum():Array{						// Get pointer position to magnitude spectrum in shared mem			magPtr = lib.getMagSpectrumC(chPtrArray[0]);			cRAM.position = magPtr;						// Reset array			magArray = [];			for(i = 0; i < Math.floor(fftSize/2); i++){							magArray.push(cRAM.readFloat());			}			return magArray;		}				/*			Group: Spectral Features					Function: getBandwidth						Calculates the spectral bandwidth for the current frame.						Returns:							The spectral bandwidth.						*/		public function getBandwidth():Number{						var band:Number;			band = lib.getBandwidthC(chPtrArray[0]);						//trace('Bandwidth DATF = ' +band);			return band;		}								/*								Function: getCentroid						Calculates the spectral centroid for the current spectral data.						Returns:							The spectral centroid.						*/		public function getCentroid():Number{						var cent:Number;			cent = lib.getCentroidC(chPtrArray[0]);						//trace('Centroid DATF = ' +cent);			return cent;		}				/*							Function: getFlux						Calculates the change in spectral energy between the current frame and the previous frame.						Returns:							The spectral flux.		*/		public function getFlux():Number{						var flux:Number;			flux = lib.getFluxC(chPtrArray[0]);						return flux;		}						/*			Function: getIntensity						Calculates the spectral intensity for the current frame.						Returns:							The spectral intensity.		*/		public function getIntensity():Number{						var inten:Number;			inten = lib.getIntensityC(chPtrArray[0]);						//trace('intensity DATF = ' +inten);			return inten;		}				/*			Function: getRolloff						Calculates the spectral rolloff for the current frame.						Returns:							The spectral rolloff.		*/		public function getRolloff():Number{						var roll:Number;			roll = lib.getRolloffC(chPtrArray[0]);						//trace('Rolloff DATF = ' +roll);			return roll;		}						/*			Group: Spectral Analysis					Function: getHarmonicAmplitudes						A function to return the amplitude of the harmonics.			Returns:							Returns an array containing the partial amplitudes populated by calling the getHarmonics function.				These amplitudes are specified in decibels (dB). Note: getHarmonics() must be called before this function				in order to populate the array with meaningful data.			See Also:							<getHarmonicFrequencies()>,				<getHarmonics()>		*/				public function getHarmonicAmplitudes():Array {			return harmAmps;		}		/*			Function: getHarmonicFrequencies						Returns an array containing the partial's frequencies populated by callilng the getHarmonics function.			The frequencies indicated are in Hertz (Hz). Note: getHarmonics() must be called before this function			in order to return meaningful data.						See Also:							<getHarmonics()>,				<getHarmonicAmplitudes()>		*/		public function getHarmonicFrequencies():Array {			return harmFreqs;		}								/*			Function: getHarmonics						Isolates the harmonics (or partials more generally speaking) of spectral data. The function operates on a			particular channel pointer in order to extract the partials from the spectrum. getHarmonics populates two			arrays: harmFreqs and harmAmps which contain the frequencies of the partials and their respective amplitudes			(in dB). Separate calls are required to retrieve harmAmps (getHarmAmps) and harmFreqs (getHarmFreqs). This			function must be called before the others to return relevant data.						Results will vary depending on a variety of factors, such as the type of spectrum (noisy or harmonic) as			well as the frameSize used to process the audio. A harmonic-like spectrum should return the fundamental			frequency as well as partials that are related by integer multiples of the fundamental (harmonics: i.e.			110Hz, 220Hz, 440Hz, ...etc). A noisy spectrum will yield non-harmoincally related peaks. Also, a large 			frameSize will tend to smear the spectral data, since the stationarity assumption does not hold over			longer time windows.						The C functioncall returns an array indicating 1) if an error was encountered 2) the number of harmonics			found (may be less than the number requested) 3) the pointer for the amplitude (peaks) array and 4) the			pointer for the frequency array						Parameters:								desiredHarms - 	An int specifying the desired number of harmonics the function should return. Int value							   	should be: 0 < desiredHarms < (frameSize/2 + 1)						See Also:							<getHarmonicFrequencies()>,				<getHarmonicAmplitudes()>		*/				public function getHarmonics(desiredHarms:uint):void {			//clear out contents of old storage arrays....			harmAmps.splice(0); harmFreqs.splice(0);						//get the returned object/Array from C....			var harmArray:Array = lib.getHarmonicsC(chPtrArray[0], desiredHarms);			var err:int = harmArray[0];						//indicates an error in the algorithmn			var numHarms:int = harmArray[1];				//the number of harmoincs found			var peaksPtr:int = harmArray[2];				//the pointer to the amplitude peaks in C memory			var freqsPtr:int = harmArray[3];				//the pointer to the freq peaks................						//trace('getHarmonics was executed with err: ' + err + ' and found ' + numHarms + ' harmonic(s)');						//how to access the found harmonics.....			var peak:Number;			var freq:Number;						for(var i:int = 0; i < numHarms; i++) {				cRAM.position = peaksPtr + sizeofFloat*i;				peak = cRAM.readFloat(); harmAmps.push(peak);				cRAM.position = freqsPtr + sizeofFloat*i;				freq = cRAM.readFloat(); harmFreqs.push(freq);				//trace('Found a harmonic at ' + freq + ' with peak: ' + peak + ' dB ');			}		}						/*			Function: getLPC						Calculates the linear prediction coefficients using Levinson-Durbin recursion.						Parameters:								order - The prediction order.		*/		public function getLPC(order:int):void {			var lpcArray:Array = lib.getLPCC(chPtrArray[0], order);			var err:int = lpcArray[0];					//indicates whether or not LPC was executed with (1) or without (0) an error			var dataPos:int = lpcArray[1];				//the position to start reading the coefficients from						//how to access the LP coeffs from memory			/*for (var i:int = 0; i < order + 1; i++) {				cRAM.position = dataPos + sizeofFloat*i;				trace('LPC coeff: ' + i + ' : ' + cRAM.readFloat());			}*/						//accessing the gain			//cRAM.position = dataPos + sizeofFloat*(order+1);			//trace('LPC gain value: ' + cRAM.readFloat());					}				/*			Function: addReverb						This function implements a well-known image model in order to simulate room reverb based on simulated			room dimensions. A filtering method in the C methods implements a fast-convolution-based filter to add			the required reverb. The reverb response is calculated based on the emitting-source's position in the			room, the room's dimensions and the listener (microphone) position. By default the reverb is applied			to the left channel when it is called.						Parameters:							activate - 	A String, either "on" or "off". This sets the state of the reverb. Once turned "on", it will remain on						  	until turned off. If "off", it will remain so until turned on.				processCh - The number of channels (1 for MONO, 2 for STEREO) to apply the reverb to.				level - A Number value that indicates the reflection strength. Possible values are integers in the range [1-4].				roomX - the width of the simulated room in the x dimension				roomY - the width of the simulated room in the y dimension				roomZ - the height of the simulated room in the z dimension				srcX - the source (audio) position in the x dimension				srcY - the source (audio) position in the y dimension				srcZ - the source (audio) position in the z dimension				micX - the mic (listener) position in the x dimension				micY - the mic (listener) position in the y dimension				micZ - the mic (listener) position in the z dimension				* all src and mic positions must be within the bounds defined by the 					simulated room dimensions.					*/				public function addReverb(activate:String, processCh:int, level:Number,							   roomX:Number, roomY:Number, roomZ:Number,							   srcX:Number, srcY:Number, srcZ:Number,							   micX:Number, micY:Number, micZ:Number):void {			var echoStrength:Number = 0;						if(processCh > numCh || processCh < 1) {				trace('invalide number of channels specified....no reverb applied'); 			}else {				for(ch = 0; ch < processCh; ch++) {					var val:int = lib.addReverbC(activate, chPtrArray[ch], roomX, roomY, roomZ,																		 srcX, srcY, srcZ,																		 micX, micY, micZ, level);				}			}		}										/*			Group: Utilities					Function: newFrame						This function resets all internal flags in the C/C++ library. This function *MUST* be called either at the end of the			current frame or at the beginning of the next frame. If it is not called, the values returned from each library function 			will be the same as the values from the previous frame. 		*/								public function newFrame():void{			lib.resetC();		}		/*					Function: clearAudioBuffers						A Function to clean out the audioBuffers at the completion of audio file playback.			Notes:						Buffers cleaned are:				* audioFrame: A buffer allocated with each channel in C that contains the samples for the current					frame to be processed and the samples for playback.				* Circular Buffers: A buffer allocated with each channel that tracks overlapping audio samples when					certain operations (i.e. filtering) are in use.		*/				public function clearAudioBuffers():void{						for(ch = 0; ch < numCh; ch++){				lib.clearAudioFrameC(chPtrArray[ch]);		//clears audioFrame (where we read/write audio to)				lib.clearAudioBufferC(chPtrArray[ch]);		//clears circularBuffers  (for filtering sequences)			}		}				/*					Function: checkAudioBuffer					A function to determine if the C-based audioFrame is ready for reading during audio playback.						Parameters:				channelType - A string indicating the desired channel to be checked. "left" and "right" are valid					arguments.								Returns:				An array containing 								* 1) A boolean indicating whether or not the audio is ready for playback and 				* 2) The number of samples that can be played if the status is "true" (i.e. its ready).		*/				public function checkAudioBuffer(channelType:String):Array {			var bufferStatus:Array;			switch(channelType) {				case "left":							bufferStatus = lib.checkAudioBufferC(chPtrArray[0]);							break;				case "right":							bufferStatus = lib.checkAudioBufferC(chPtrArray[1]);							break;				default:							trace('invalid channel type');			}						return bufferStatus;					}	}}